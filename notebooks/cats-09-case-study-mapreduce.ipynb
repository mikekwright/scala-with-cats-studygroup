{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: MapReduce\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case study we are going to look at the very popular concept of **MapReduce**.  This is a commonly used technique in the industry, especially when working with big data.  There are a lot of common tools out there that support this paradigm, a really popular one is **Spark**.  \n",
    "\n",
    "The basic idea is easy to decipher from the name itself, it we pull it apart into _Map_ and _Reduce_ what we have are two main operations. \n",
    "\n",
    "1. **Map** which is to iterate over a list of values and return some value\n",
    "2. **Reduce** apply an operation on all and return a smaller list of the results (combined, grouped, etc).\n",
    "\n",
    "These functional paradigms exists in scala and **Map** would most closely relate to the `map` function in scala, and **Reduce** would be `fold`.  \n",
    "\n",
    "![MapReduce - foldMap](images/foldmap.png)\n",
    "\n",
    "Lets start by making sure we have everything loaded/imported that we need in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.typelevel::cats-core:2.0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Required to enable the higher kinded types in scala (support for F[_])\n",
    "import scala.language.higherKinds\n",
    "\n",
    "import scala.concurrent._\n",
    "import scala.concurrent.duration._\n",
    "\n",
    "import scala.concurrent.Future\n",
    "import scala.concurrent.ExecutionContext.Implicits.global\n",
    "\n",
    "import cats.{Monad, Monoid}\n",
    "import cats.syntax.semigroup._ // for |+|\n",
    "import cats.instances.int._ // for Monoid\n",
    "import cats.instances.string._ // for Monoid\n",
    "import cats.instances.future._ // for Applicative\n",
    "import cats.instances.list._ // for Traverse\n",
    "import cats.syntax.traverse._ // for sequence\n",
    "import cats.instances.int._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin our discussion, lets make sure that we have a clear understanding of what the map function's signature looks like.  In a general sense, it is applying a function `A => B` to an `F[A]` which should return an `F[B]`.  \n",
    "\n",
    "Below is an illustration of this signature (from the cats book).  \n",
    "\n",
    "![Cats Image - MapReduce Functor and Fold](images/mapreduce-functor.png)\n",
    "\n",
    "So any data type that has both the type classes, _functor_ and _foldable_, can be setup for map-reduce.  There is one caveat as well, when we are running the traversal, we will lose control over the order that items are applied, and so we will need to make sure that we are also **associative** (and, of course, identity): \n",
    "\n",
    "```scala\n",
    "reduce(a1, reduce(a2, a3)) == reduce(reduce(a1, a2), a3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Foldmap\n",
    "\n",
    "To start, lets implement foldmap.  The foldmap implementation, is basically a small map-reduce in and of itself, but run on one thread.  Lets first start by defining the signature to do the following. \n",
    "\n",
    "• accept a sequence of type `Vector[A]`\n",
    "• accept a func on of type `A => B` , where there is a Monoid for `B`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def foldMap[A, B: Monoid](values: Vector[A])(func: A => B): B = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with our given signature, lets add the following to the body:\n",
    "\n",
    "1. start with a sequence of items of type A\n",
    "2. map over the list to produce a sequence of items of type B\n",
    "3. use the Monoid to reduce the items to a single B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def foldMap[A, B : Monoid](as: Vector[A])(func: A => B): B = as.map(func).foldLeft(Monoid[B].empty)(_ |+| _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, lets quickly try out our implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldMap(Vector(1, 2, 3))(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldMap(Vector(1, 2, 3))(_.toString + \"! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldMap(\"Hello world!\".toVector)(_.toString.toUpperCase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributing the operation\n",
    "\n",
    "Our simple map reduce implementation above is great, but not necessarily the most efficient for a given machine.  Instead, we should attempt to utilize all of the processing power that we have available on the box which can only be accomplished if we start to divide up the data and distribute the operation to multiple cores/thread.  \n",
    "\n",
    "![Distribute MapReduce](images/parallelising-foldmap.png)\n",
    "\n",
    "We can accomplish the distributed work by using Scala's `Future` which work using thread pools.  To start dividing our work we want to try to utilize the number of available processors (instead of hard coding the value).  So lets first check and see how many available processors we have.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val processorCount = Runtime.getRuntime.availableProcessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that we have our processor count we can group our initial data request into buckets of the same count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 to 100).toList.grouped(processorCount).toList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Foldmap\n",
    "\n",
    "Lets start on our implementation of parallelfoldmap by defining the signature.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelFoldMap[A, B : Monoid](values: Vector[A])(func: A => B): Future[B] = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelFoldMap[A, B: Monoid](values: Vector[A])(func: A => B): Future[B] = {\n",
    "    val numCores = Runtime.getRuntime.availableProcessors\n",
    "    val groupSize = (1.0 * values.size / numCores).ceil.toInt\n",
    "    val groups: Iterator[Vector[A]] = values.grouped(groupSize)\n",
    "\n",
    "    val futures: Iterator[Future[B]] = groups map { \n",
    "        group =>\n",
    "            Future {\n",
    "                group.foldLeft(Monoid[B].empty)(_ |+| func(_))\n",
    "            }\n",
    "        }\n",
    "\n",
    "    Future.sequence(futures) map { iterable => iterable.foldLeft(Monoid[B].empty)(_ |+| _)\n",
    "    }\n",
    "}\n",
    "\n",
    "val result: Future[Int] = parallelFoldMap((1 to 1000000).toVector)(identity)\n",
    "Await.result(result, 1.second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book also provides an implementation that uses as much Cats as possible, to demonstrate how consice the solution can be.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelFoldMap[A, B: Monoid](values: Vector[A])(func: A => B): Future[B] = {\n",
    "    val numCores = Runtime.getRuntime.availableProcessors\n",
    "    val groupSize = (1.0 * values.size / numCores).ceil.toInt\n",
    "\n",
    "    values.grouped(groupSize).toVector.traverse(group => Future(group.toVector.foldMap(func))).map(_.combineAll)\n",
    "}\n",
    "\n",
    "val future: Future[Int] = parallelFoldMap((1 to 1000).toVector)(_ * 1000)\n",
    "Await.result(future, 1.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
